{"cells":[{"cell_type":"markdown","metadata":{"id":"YKjVXkOq5RvM"},"source":["# Prediction"]},{"cell_type":"markdown","source":["Outcome to be predicted: $Y_i$\n","> *example:* a worker's log wage\n","\n","Characteristics (aka **features**): $X_i=\\left(X_{1i},\\ldots,X_{pi}\\right)'$\n","> *example:* education, age, state of birth, parents' education, cognitive ability, family background\n"],"metadata":{"id":"KhnbzPkYx-k9"}},{"cell_type":"code","source":["%matplotlib inline\n","# give notebook access to google drive:\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd '/content/gdrive/My Drive/mixtape ML+causal'\n","\n","# import some useful packages\n","import pandas as pd\n","import numpy as np\n","from sklearn import linear_model\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GridSearchCV\n","import warnings\n","warnings.filterwarnings('ignore')\n","from sklearn.model_selection import train_test_split\n","\n","\n","plt.style.use('seaborn-whitegrid')\n","\n","# read in data\n","nlsy=pd.read_csv('data/nlsy97.csv')\n","nlsy"],"metadata":{"id":"7IIIROqHoI4g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Least squares benchmark"],"metadata":{"id":"wizaAK2iRf95"}},{"cell_type":"code","source":["# generate dictionary of transformations of education\n","powerlist=[nlsy['educ']**j for j in np.arange(1,10)]\n","X=pd.concat(powerlist,axis=1)\n","X.columns = ['educ'+str(j) for j in np.arange(1,10)]\n","# standardize our X matrix (doesn't matter for OLS, but will matter for lasso below)\n","scaler = StandardScaler()\n","scaler.fit(X)\n","X_scaled = scaler.transform(X)\n","\n","# run least squares regression\n","reg=linear_model.LinearRegression().fit(X_scaled,nlsy['lnw_2016'])\n","yhat=reg.predict(X_scaled)\n"],"metadata":{"id":"25-Dc3CdTQ-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot predicted values\n","lnwbar=nlsy.groupby('educ')['lnw_2016'].mean()\n","Xbar=pd.DataFrame({'educ':lnwbar.index.values})\n","powerlist=[Xbar['educ']**j for j in np.arange(1,10)]\n","Xbar=pd.concat(powerlist,axis=1)\n","Xbar.columns = X.columns\n","Xbar_scaled = scaler.transform(Xbar)\n","ybarhat=reg.predict(Xbar_scaled)\n","fig = plt.figure()\n","ax = plt.axes()\n","ax.plot(Xbar['educ1'],lnwbar,'bo',Xbar['educ1'],ybarhat,'g-');\n","plt.title(\"ln Wages by Education in the NLSY\")\n","plt.xlabel(\"years of schooling\")\n","plt.ylabel(\"ln wages\");"],"metadata":{"id":"WwPztFomD_I_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As we can see, least squares linear regression can approximate any continuous function and can certainly be used for prediction. Include a rich enough set of transformations, and OLS predictions will yield unbiased estimates of the true ideal predictor, the conditional expectation function. But these estimates will be quite noisy. Penalized regression can greatly reduce the variance, at the expense of some bias. But if the bias reduction is great enough, the predictions can have lower MSE. Back to the whiteboard!\n"],"metadata":{"id":"mtllIvMQ1V8X"}},{"cell_type":"markdown","source":["## Lasso in action"],"metadata":{"id":"eJZrKXiFRowv"}},{"cell_type":"markdown","source":["Welcome back! Let's see lasso in action:"],"metadata":{"id":"3zrJPzaPCkrm"}},{"cell_type":"code","source":["# fit lasso with a couple of different alphas and plot results\n","lasso1 = linear_model.Lasso(alpha=.001,max_iter=1000).fit(X_scaled,nlsy['lnw_2016'])\n","ybarhat1=lasso1.predict(Xbar_scaled)\n","lasso2 = linear_model.Lasso(alpha=.01,max_iter=1000).fit(X_scaled,nlsy['lnw_2016'])\n","ybarhat2=lasso2.predict(Xbar_scaled)\n"],"metadata":{"id":"WpeyLwK8iV6k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plot results"],"metadata":{"id":"FcrrwylQx0FI"}},{"cell_type":"code","source":["#@title\n","fig1,(ax11,ax12,ax13) = plt.subplots(1,3,figsize=(12, 4))\n","ax11.barh(Xbar.columns,reg.coef_,align='center');\n","ax11.set_title(\"OLS coefficients\")\n","ax11.set_xlabel(\"coefficient\")\n","ax12.barh(Xbar.columns,lasso1.coef_,align='center');\n","ax12.set_title(\"Lasso coefficients (alpha = {:.3f})\".format(lasso1.get_params()['alpha']))\n","ax12.set_xlabel(\"coefficient\")\n","ax13.barh(Xbar.columns,lasso2.coef_,align='center');\n","ax13.set_title(\"Lasso coefficients (alpha = {:.2f})\".format(lasso2.get_params()['alpha']))\n","ax13.set_xlabel(\"coefficient\")\n","fig2,(ax21,ax22,ax23) = plt.subplots(1,3,figsize=(12,4))\n","ax21.plot(Xbar['educ1'],lnwbar,'bo',Xbar['educ1'],ybarhat,'g-');\n","ax21.set_title(\"ln Wages by Education in the NLSY\")\n","ax21.set_xlabel(\"years of schooling\")\n","ax21.set_ylabel(\"ln wages\");\n","ax22.plot(Xbar['educ1'],lnwbar,'bo',Xbar['educ1'],ybarhat1,'g-');\n","ax22.set_title(\"ln Wages by Education in the NLSY\")\n","ax22.set_xlabel(\"years of schooling\")\n","ax22.set_ylabel(\"ln wages\");\n","ax23.plot(Xbar['educ1'],lnwbar,'bo',Xbar['educ1'],ybarhat2,'g-');\n","ax23.set_title(\"ln Wages by Education in the NLSY\")\n","ax23.set_xlabel(\"years of schooling\")\n","ax23.set_ylabel(\"ln wages\");"],"metadata":{"cellView":"form","id":"-Vk_qSIzxwsi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Play around with different values for alpha to see how the fit changes!"],"metadata":{"id":"osbAl2I0znmx"}},{"cell_type":"markdown","source":["### Data-driven tuning parameters: Cross-validation"],"metadata":{"id":"WLGCHAGPnce4"}},{"cell_type":"code","source":["# define grid for alpha\n","alpha_grid = {'alpha': [.0001,.001,.002, .004, .006, .008, .01, .012, .014, .016 ,.018, .02 ],'max_iter': [100000]}\n","grid_search = GridSearchCV(linear_model.Lasso(),alpha_grid,cv=5,return_train_score=True).fit(X_scaled,nlsy['lnw_2016'])\n","print(\"Best alpha: \",grid_search.best_estimator_.get_params()['alpha'])"],"metadata":{"id":"YVaN9tFwnyMv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Lasso-guided variable selection\n","For illustrative purposes we've been using lasso to determine the functional form for a single underlying regressor: education. But lasso's real power comes in selecting among a large number of regressors."],"metadata":{"id":"Q7r54SvPDz6P"}},{"cell_type":"code","source":["# Define \"menu\" of regressors:\n","X=nlsy.drop(columns=['lnw_2016','exp'])\n","\n","# Divide into training and test set\n","X_train, X_test, y_train, y_test = train_test_split(X, nlsy['lnw_2016'],random_state=42)\n","# Scale regressors\n","scaler.fit(X_train)\n","X_train_scaled = scaler.transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","# Do cross-validated Lasso (the easy way!)\n","lassocv=linear_model.LassoCV(random_state=42).fit(X_train_scaled,y_train)\n","print(\"Number of regressors in the menu: \",len(X.columns))\n","print(\"Number of regressors selected by lasso: \",sum(lassocv.coef_!=0))\n","# look at the coefficients\n","results = pd.DataFrame({'feature': X.columns[lassocv.coef_!=0],'coefficient': lassocv.coef_[lassocv.coef_!=0]})\n","results"],"metadata":{"id":"gZyPjQ6XIIuD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["To try on your own: load the Oregon HIE data from earlier and try lassoing the OLS regression we did there. What do you notice?\n"],"metadata":{"id":"YDMH-869NLKF"}},{"cell_type":"code","source":["# Load Oregon HIE data . . ."],"metadata":{"id":"eczzwQy0R9Cu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Connection to ML"],"metadata":{"id":"FDNSEcQYwfhC"}},{"cell_type":"markdown","source":["Where does machine learning fit into this? It might be tempting to treat\n","this regression as a prediction exercise where we are predicting $Y_{i}$\n","given $D_{i}$ and $X_{i}$. Don't give in to this temptation. We are not\n","after a prediction for $Y_{i}$, we are after a coefficient on $D_{i}$.\n","Modern machine learning algorithms are finely tuned for producing\n","predictions, but along the way they compromise coefficients. So how can we\n","deploy machine learning in the service of estimating the causal coefficient $\\delta $?\n","\n","To see where ML fits in, first remember that an equivalent way to estimate $%\n","\\delta $ is the following three-step procedure:\n","\n","\n","1.   Regress $Y_{i}$ on $X_{i}$ and compute the residuals, $\\tilde{Y}%\n","_{i}=Y_{i}-\\hat{Y}_{i}^{OLS}$, where $\\hat{Y}_{i}^{OLS}=X_{i}^{\\prime\n","}\\left( X^{\\prime }X\\right) ^{-1}X^{\\prime }Y$\n","2.   Regress $D_{i}$ on $X_{i}$ and compute the residuals, $\\tilde{D}%\n","_{i}=D_{i}-\\hat{D}_{i}^{OLS}$, where $\\hat{D}_{i}^{OLS}=X_{i}^{\\prime\n","}\\left( X^{\\prime }X\\right) ^{-1}X^{\\prime }D$\n","\n","3. Regress $\\tilde{Y}_{i}$ on $\\tilde{D}_{i}$.\n","\n","Let's try it!"],"metadata":{"id":"fLMqhUEDwRzf"}},{"cell_type":"code","source":["# Regress outcome on covariates\n","yreg=linear_model.LinearRegression().fit(x,y,w)\n","# Calculate residuals\n","ytilde = y - yreg.predict(x)\n","\n","# regress treatment on covariates\n","dreg = linear_model.LinearRegression().fit(x,d,w)\n","# Calculate residuals\n","dtilde = d - dreg.predict(x)\n","\n","# regress ytilde on dtilde\n","lm.fit(dtilde,ytilde,w)\n","print(\"Estimated effect of Medicaid elibility on \\n number of doctor visits\" +\n","      \" (partialled out): {:.3f}\".format(lm.coef_[0]))"],"metadata":{"id":"ZdupDB5PuKEW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ML enters the picture by providing an alternate way to generate $\\hat{Y}_i$ and $\\hat{D}_i$ when OLS is not the best tool for the job. The first two steps are really just prediction exercises, and in principle any supervised machine learning algorithm can step in here. Back to the whiteboard!"],"metadata":{"id":"jseTbw6nxrY9"}},{"cell_type":"code","source":[],"metadata":{"id":"iVsT1WDaNAm6"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[{"file_id":"1AC4pReS_CGnqgSQqM8yHB5iwzJDK48_K","timestamp":1666389241335}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}